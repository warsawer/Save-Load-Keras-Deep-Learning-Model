{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Save Your Neural Network Model to JSON"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load pima indians dataset\n",
    "\"\"\" dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\") \"\"\"\n",
    "dataset = pd.read_csv('.../data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# later...\n",
    "\n",
    "# load JSON and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# @classmethod\n",
    "# def from_config(cls, config):\n",
    "#   return cls(**config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 77.18%\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "accuracy: 77.18%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Your Neural Network Model to YAML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# MLP for Pima Indians Dataset Serialize to YAML and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load pima indians dataset\n",
    "\"\"\" dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\") \"\"\"\n",
    "dataset = pd.read_csv('.../data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# later...\n",
    "\n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 77.84%\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "accuracy: 77.84%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model Weights and Architecture Together (H5 file)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to Save a Keras Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# MLP for Pima Indians Dataset saved to a single file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load pima indians dataset\n",
    "\"\"\" dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\") \"\"\"\n",
    "dataset = pd.read_csv('.../data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# Save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 74.58%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to Load a Keras Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# load and evaluate a saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model= load_model('model.h5')\n",
    "# summarize model\n",
    "model.summary()\n",
    "# load dataset\n",
    "dataset = pd.read_csv('.../data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 74.58%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit"
  },
  "interpreter": {
   "hash": "7c0ee5a748d2f3e1fdd2501a02c19249aff4e1a7f2ffbefb0401640bad97d954"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}